# CAFA-6 Protein Function Prediction (AI-driven Development)

This repository is designed for **AI-driven development** of a protein function
prediction system for the Kaggle CAFA-6 competition.

**Competition Link**: https://www.kaggle.com/competitions/cafa-6-protein-function-prediction/overview

---

## ğŸ¯ Project Goal

Predict Gene Ontology (GO) terms for proteins using:

- Amino acid sequences
- (Optional) taxonomy / species information


---

## âŒ Non-Goals (Important)

This repository is **NOT** intended to:

- Train very large end-to-end models from scratch
- Perform heavy hyperparameter searches inside Kaggle
- Mix experimental notebook code with production code

---

## ğŸ§  AI Development Policy

When modifying or extending this repository, **AI agents must follow these rules**:

1. All reusable logic must be implemented under `src/`
2. Notebooks are for exploration only (no core logic)
3. File paths and parameters must be configurable via `configs/`
4. Cached artifacts (embeddings, models) must be saved explicitly
5. Code should favor clarity and debuggability over extreme optimization

---

## ğŸ“¦ Dataset Overview

The dataset is designed for **multi-label protein function prediction** using Gene Ontology (GO) terms.

### Key Files

| File | Description |
|------|-------------|
| `train_sequences.fasta` | Protein amino acid sequences (training) |
| `train_terms.tsv` | Ground truth GO term annotations |
| `train_taxonomy.tsv` | Taxonomy (species) information for proteins |
| `go-basic.obo` | Gene Ontology hierarchy structure |
| `testsuperset.fasta` | Test protein sequences for prediction |
| `testsuperset-taxon-list.tsv` | Taxonomy IDs for test proteins |
| `IA.tsv` | Information Accretion weights for GO terms |
| `sample_submission.tsv` | Submission format template |

### Important Notes

- **Multi-label problem**: Each protein can have multiple GO terms
- **Hierarchical structure**: GO terms are organized in an ontology
- **Taxonomy is optional**: Species information may improve predictions

### Data Statistics (from `src/main.ipynb` analysis)

**Training Sequences:**
- Number of sequences: 82,403
- Sequence length distribution:
  - Min: 16 amino acids
  - Max: 10,000+ amino acids
  - Mean: ~400-500 amino acids
  - 25th percentile: ~200 aa
  - 50th percentile (median): ~350 aa
  - 75th percentile: ~550 aa
  - 90th percentile: ~800 aa
  - 95th percentile: ~1,100 aa
  - 99th percentile: ~2,000 aa
- Long sequences (>10,000 aa): A small number exist

**Test Data:**
- Species distribution (from `testsuperset-taxon-list.tsv`):
  - Human (Homo sapiens, 9606)
  - Rat (Rattus norvegicus, 10116)
  - Rice (Oryza sativa subsp. japonica, 39947)
  - Zebrafish (Danio rerio, 7955)
  - Fruit fly (Drosophila melanogaster, 7227)

**GO Terms:**
- GO ontology structure includes:
  - `id`: GO term identifier (e.g., GO:0000001)
  - `name`: Term name (e.g., "mitochondrion inheritance")
  - `namespace`: biological_process, molecular_function, or cellular_component
  - `is_a`: Parent-child relationships in the ontology
  - `def`: Definition with references

**Submission Format:**
- The submission file contains both GO term predictions and free-text descriptions
- Two types of rows per protein:
  - GO term rows: `protein_id`, `GO:XXXXXXX`, `score` (0-1)
  - Text description rows: `protein_id`, `Text`, `score`, `description`


## ğŸ“ Project Structure

```
Kaggle_CAFA6/
â”œâ”€â”€ input/                          # Competition data files
â”‚   â””â”€â”€ cafa-6-protein-function-prediction/
â”‚       â”œâ”€â”€ Train/                  # Training data
â”‚       â”‚   â”œâ”€â”€ train_sequences.fasta
â”‚       â”‚   â”œâ”€â”€ train_terms.tsv
â”‚       â”‚   â”œâ”€â”€ train_taxonomy.tsv
â”‚       â”‚   â””â”€â”€ go-basic.obo
â”‚       â”œâ”€â”€ Test/                   # Test data
â”‚       â”‚   â”œâ”€â”€ testsuperset.fasta
â”‚       â”‚   â””â”€â”€ testsuperset-taxon-list.tsv
â”‚       â”œâ”€â”€ IA.tsv                  # GO term weights
â”‚       â””â”€â”€ sample_submission.tsv
â”œâ”€â”€ src/                            # Source code (reusable logic)
â”‚   â””â”€â”€ main.ipynb                  # Main notebook for Kaggle submission
â”œâ”€â”€ model/                          # Pre-trained model weights
â”‚   â”œâ”€â”€ esm2_t12_35M_UR50D/        # ESM2 protein embedding model
â”‚   â”œâ”€â”€ esm2_t30_150M_UR50D/
â”‚   â”œâ”€â”€ esm2_t33_650M_UR50D/
â”‚   â””â”€â”€ BiomedNLP-BiomedBERT-base-uncased-abstract/  # BiomedBERT for GO text
â”œâ”€â”€ output/                         # Generated embeddings and predictions
â”œâ”€â”€ pyproject.toml                  # Project dependencies (uv)
â””â”€â”€ README.md
```

---

## ğŸ§  Modeling Approach

This repository adopts a **dual-embedding (dual-encoder) approach** for protein
function prediction.

Instead of directly classifying proteins into a fixed set of GO labels,
we embed **proteins** and **GO terms** into a shared latent space and train a model
to align them.

---

### 1. Protein Embedding

- Each protein is represented by its amino acid sequence.
- Sequences are encoded using a pretrained protein language model
  (e.g. ESM-2).
- The output is a fixed-dimensional vector representing the protein.

This embedding captures:
- sequence patterns
- evolutionary and structural signals
- biochemical properties learned from large protein databases

---

### 2. GO Term Embedding

- Each Gene Ontology (GO) term is also represented as a vector.
- GO embeddings are obtained separately (e.g. from text descriptions,
  ontology structure, or a pretrained language model).
- All GO terms are embedded into the same dimensional space.

This allows the model to:
- reason about similarities between GO terms
- generalize across related biological functions

---

### 3. Shared Latent Space

Both protein embeddings and GO embeddings are projected into a **shared latent space**
using lightweight neural networks (typically linear layers).

Let:
- `h_p` be the protein embedding
- `h_go` be the GO term embedding

Then:
- `z_p = f_p(h_p)`  
- `z_go = f_go(h_go)`

where `f_p` and `f_go` are learnable projection functions.

---

### 4. Training Objective

The model is trained to **bring related proteinâ€“GO pairs closer together**
in the latent space, while pushing unrelated pairs further apart.

Intuitively:
- If a protein is annotated with a GO term, their embeddings should be similar.
- If not, their embeddings should be dissimilar.

This alignment objective can be implemented using:
- similarity scores (e.g. dot product or cosine similarity)
- multi-label losses (e.g. BCE over proteinâ€“GO pairs)

---

### 5. Inference

At inference time:
1. Embed the protein sequence.
2. Compare it against all GO term embeddings.
3. Rank GO terms by similarity score.
4. Output GO terms and confidence scores in Kaggle submission format.

---

### Design Rationale

This embedding-based formulation offers several advantages:

- Scalability to large GO vocabularies
- Flexibility to incorporate GO semantics
- Efficient reuse of cached embeddings
- Clear separation between representation learning and prediction logic

This design is particularly suitable for:
- AI-assisted iterative development
- constrained execution environments (e.g. Kaggle notebooks)

---

## ğŸ› ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ç’°å¢ƒæ§‹ç¯‰

1. **uvã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   uv --version
   ```

2. **ä»®æƒ³ç’°å¢ƒä½œæˆ**
   ```bash
   uv venv
   ```

3. **ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–**
   ```bash
   source .venv/bin/activate
   ```

4. **ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
   ```bash
   uv pip install -e .
   ```

### 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

Kaggleã‹ã‚‰ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`input/cafa-6-protein-function-prediction/`ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚

```bash
# Kaggle CLIã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
kaggle competitions download -c cafa-6-protein-function-prediction
unzip cafa-6-protein-function-prediction.zip -d input/cafa-6-protein-function-prediction/
```

### 3. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã®ãƒ¬ãƒã‚¸ãƒˆãƒªã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯**Gitã§ç®¡ç†ã—ã¦ã„ã¾ã›ã‚“**ï¼ˆã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ï¼‰ã€‚
ä»¥ä¸‹ã®æ‰‹é †ã§ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³A: Hugging Face Hubã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰

```python
from transformers import AutoModel, AutoTokenizer

# ESM2ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªåŸ‹ã‚è¾¼ã¿ç”¨ï¼‰
model_name = "facebook/esm2_t12_35M_UR50D"
model = AutoModel.from_pretrained(model_name, cache_dir="./model")
tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="./model")

# BiomedBERTãƒ¢ãƒ‡ãƒ«ï¼ˆGO termåŸ‹ã‚è¾¼ã¿ç”¨ï¼‰
model_name = "microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract"
model = AutoModel.from_pretrained(model_name, cache_dir="./model")
tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="./model")
```

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³B: ãƒ­ãƒ¼ã‚«ãƒ«ã®zipãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è§£å‡

`model/zips/`ã«ãƒ¢ãƒ‡ãƒ«ã®zipãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆï¼š

```bash
# model/zipsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd model/zips

# å„ãƒ¢ãƒ‡ãƒ«ã‚’è§£å‡
unzip esm2_t12_35M_UR50D.zip -d ../esm2_t12_35M_UR50D/
unzip BiomedNLP-BiomedBERT-base-uncased-abstract.zip -d ../BiomedNLP-BiomedBERT-base-uncased-abstract/

# å¿…è¦ã«å¿œã˜ã¦ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚‚è§£å‡
# unzip esm2_t30_150M_UR50D.zip -d ../esm2_t30_150M_UR50D/
# unzip esm2_t33_650M_UR50D.zip -d ../esm2_t33_650M_UR50D/

cd ../..
```

#### å¿…è¦ãªãƒ¢ãƒ‡ãƒ«

ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼š
- `facebook/esm2_t12_35M_UR50D` - ã‚¿ãƒ³ãƒ‘ã‚¯è³ªé…åˆ—ã®åŸ‹ã‚è¾¼ã¿ç”¨
- `microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract` - GO termåŸ‹ã‚è¾¼ã¿ç”¨

**æ³¨æ„**: `model/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã¯`.gitignore`ã§é™¤å¤–ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯Gitã«ã‚³ãƒŸãƒƒãƒˆã•ã‚Œã¾ã›ã‚“ã€‚

## To Do

### ãƒ•ã‚©ãƒ«ãƒ€æ•´ç†

main.ipynbã«æ©Ÿèƒ½ãŒé›†ä¸­ã—ã™ãã¦ã„ã‚‹
stepã”ã¨ã«.pyãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€é–¢æ•°ã‚„ã‚¯ãƒ©ã‚¹ã‚’ç®¡ç†ã™ã‚‹

---

### å¾Œå‡¦ç†ã®è¿½åŠ 

GOã¯éšå±¤çš„ãªæ§‹é€ ã‚’æŒã¤ã€‚
ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã§ã¨ã‚ã‚‹GO, GO_aã§ã‚ã‚‹ç¢ºç‡ãŒ1ã«è¿‘ã„æ™‚ã€ãã®ä¸Šä½æ¦‚å¿µ(is_a)ã®ç¢ºç‡ã‚‚1ã«è¿‘ã„ã®ãŒè‡ªç„¶ã§ã‚ã‚‹ã€‚
é€†ã‚‚ã¾ãŸç„¶ã‚Šã§ã€GO_aã®ç¢ºç‡ãŒ0ã«è¿‘ã„æ™‚ã€ãã®ä¸‹ä½æ¦‚å¿µã‚‚0ã«è¿‘ã„ã®ãŒè‡ªç„¶ã§ã‚ã‚‹ã€‚
ã“ã®è£œæ­£ã®å®Ÿè£…ã«ã¯ã€ä»¥ä¸‹ã®2ã¤ã®è¨­è¨ˆã®ã©ã¡ã‚‰ã‹ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
1. ã¨ã‚ã‚‹ä¸‹ä½GOã®ç¢ºç‡ãŒé«˜ã„æ™‚,ãã®ä¸Šä½GOã®ç¢ºç‡ã‚’å¼•ãä¸Šã’ã‚‹
2. ã¨ã‚ã‚‹ä¸Šä½GOã®ç¢ºç‡ãŒä½ã„æ™‚,ãã®ä¸‹ä½GOã®ç¢ºç‡ã‚’å¼•ãä¸‹ã’ã‚‹

---

### JointModelã®æ”¹å–„

JointModelã¯äºŒã¤ã®Embeddingã‚’å˜ç´”ãªç·šå‹çµåˆå±¤ä¸€ã¤ã§å¤‰æ›ã™ã‚‹ã‹ãªã‚Šå˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚
ã‚‚ã†å°‘ã—è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã«ã™ã‚‹ã“ã¨ã§ç²¾åº¦æ”¹å–„ãŒæœŸå¾…ã§ãã‚‹ã€‚
å…·ä½“çš„ã«ã¯Transformerã®Attentionæ©Ÿæ§‹ã‚’ä¸€å±¤ã§ã„ã„ã®ã§è¿½åŠ ã§ãã‚‹ã¨è‰¯ã„ã¨è€ƒãˆã¦ã„ã‚‹ã€‚
ä½•æ•…ãªã‚‰ã€æœ¬ã‚¿ã‚¹ã‚¯ã®ç›®çš„ã¯æœ¬è³ªçš„ã«ã‚¢ãƒŸãƒé…¸é…åˆ—ã¨ãã‚Œã«å¯¾å¿œã™ã‚‹è¾æ›¸ã‚’ä½œæˆã™ã‚‹ã“ã¨ã«è¿‘ä¼¼ã§ãã€ãã‚Œã¯Attentionæ©Ÿæ§‹ã®key, valueã«å¯¾å¿œã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚

---

### æ¨è«–æ™‚é–“çŸ­ç¸®

ç‰¹ã«esm2ã«ã‚ˆã‚‹æ¨è«–éƒ¨åˆ†ã«å¤§ããªæ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã€‚
ã“ã®éƒ¨åˆ†ã®æ¨è«–æ™‚é–“çŸ­ç¸®ã«æˆåŠŸã™ã‚Œã°ã€ãã®åˆ†ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä»–ã«å›ã›ã‚‹

--- 

### ä½¿ã£ã¦ã„ãªã„inputã®ä½¿ç”¨

ç¾åœ¨ã¯inputã®ä¸­ã§ã‚‚ä½¿ã£ã¦ã„ãªã„æƒ…å ±ãŒå¤šæ•°ã‚ã‚‹ã€‚
ã“ã‚Œã‚‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§æœ€çµ‚çš„ãªoutputã®ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã‚‹ã€‚
ä½¿ç”¨æ–¹æ³•ã¯å¿…ãšã—ã‚‚æ©Ÿæ¢°å­¦ç¿’ã‚„æ·±å±¤å­¦ç¿’çš„æ‰‹æ³•ã«é™ã‚‰ãšã€å‰å‡¦ç†ã‚„å¾Œè¿°ã™ã‚‹å¾Œå‡¦ç†ã¸ã®ä½¿ç”¨ã‚‚æ¤œè¨ã•ã‚Œã‚‹ã€‚
ãŸã ã—ã€testæ™‚ã«ä½¿ãˆãªã„æƒ…å ±ã®æ‰±ã„ã«ã¯æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚

#### 1. `IA.tsv` (Information Accretion weights)
- **å†…å®¹**: å„GO termã«å¯¾ã™ã‚‹é‡è¦åº¦ã‚¹ã‚³ã‚¢(Information Accretion)
- **ç”¨é€”**:
  - è©•ä¾¡æŒ‡æ¨™ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹(ã‚³ãƒ³ãƒšã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«é–¢é€£)
  - äºˆæ¸¬æ™‚ã®é–¾å€¤èª¿æ•´: IAå€¤ãŒé«˜ã„GO termã¯äºˆæ¸¬ã‚’æ…é‡ã«è¡Œã†
  - æå¤±é–¢æ•°ã®é‡ã¿ä»˜ã‘: IAå€¤ã«å¿œã˜ã¦æå¤±ã«é‡ã¿ã‚’ä»˜ã‘ã‚‹
  - ã‚¹ã‚³ã‚¢ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: é‡è¦ãªGO termã®äºˆæ¸¬ç¢ºç‡ã‚’èª¿æ•´
- **æ³¨æ„**: trainã¨testã®ä¸¡æ–¹ã§ä½¿ç”¨å¯èƒ½

#### 2. `testsuperset-taxon-list.tsv` (ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿç‰©ç¨®æƒ…å ±)
- **å†…å®¹**: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å„ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®ç”Ÿç‰©ç¨®(taxonomy ID)
- **ç”¨é€”**:
  - ç”Ÿç‰©ç¨®åˆ¥ã®ãƒ¢ãƒ‡ãƒ«é¸æŠã‚„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
  - ç”Ÿç‰©ç¨®å›ºæœ‰ã®GO termå‚¾å‘ã‚’æ´»ç”¨ã—ãŸå¾Œå‡¦ç†
  - ç”Ÿç‰©ç¨®æƒ…å ±ã‚’æ¡ä»¶ä»˜ã‘å¤‰æ•°ã¨ã—ã¦ä½¿ç”¨(conditional prediction)
- **æ³¨æ„**: testæ™‚ã«ä½¿ç”¨å¯èƒ½ãªã®ã§ç©æ¥µçš„ã«æ´»ç”¨ã™ã¹ã

#### 3. `train_taxonomy.tsv` (è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿç‰©ç¨®æƒ…å ±)
- **å†…å®¹**: è¨“ç·´ã‚»ãƒƒãƒˆã®å„ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®ç”Ÿç‰©ç¨®(taxonomy ID)
- **ç”¨é€”**:
  - ç”Ÿç‰©ç¨®æƒ…å ±ã‚’ã‚¿ãƒ³ãƒ‘ã‚¯è³ªembeddingã«è¿½åŠ (concatenateã¾ãŸã¯cross-attention)
  - ç”Ÿç‰©ç¨®ã”ã¨ã®GO termåˆ†å¸ƒã®å­¦ç¿’
  - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: ç”Ÿç‰©ç¨®æƒ…å ±ã‚’ãƒã‚¹ã‚¯ã—ãŸã‚Šæ‘‚å‹•ã•ã›ã‚‹
  - å±¤åˆ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: ç”Ÿç‰©ç¨®ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸå­¦ç¿’
- **æ³¨æ„**: trainã®ã¿ã§ä½¿ç”¨å¯èƒ½ã€‚testã§ã¯`testsuperset-taxon-list.tsv`ã‚’ä½¿ç”¨

#### 4. `train_terms.tsv`ã®aspectåˆ—
- **å†…å®¹**: å„GO termã®ç¨®é¡(biological_process / molecular_function / cellular_component)
- **ç”¨é€”**:
  - aspectåˆ¥ã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰: 3ã¤ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
  - aspectåˆ¥ã®æå¤±è¨ˆç®—: å„aspectã§ç•°ãªã‚‹é‡ã¿ã‚„é–¾å€¤ã‚’ä½¿ç”¨
  - äºˆæ¸¬ã®åˆ¶ç´„: ç”Ÿç‰©å­¦çš„ã«çŸ›ç›¾ã™ã‚‹aspectã®çµ„ã¿åˆã‚ã›ã‚’æ’é™¤
  - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: aspectåˆ¥äºˆæ¸¬ã‚’çµ±åˆ
- **æ³¨æ„**: `go-basic.obo`ã®namespaceæƒ…å ±ã¨å¯¾å¿œã—ã¦ã„ã‚‹

#### 5. FASTAå½¢å¼ã®ã‚¢ãƒŸãƒé…¸é…åˆ—ä»¥å¤–ã®æƒ…å ±
- **å†…å®¹**: FASTAãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã¾ã‚Œã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿(é…åˆ—IDã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç­‰)
- **ç”¨é€”**:
  - é…åˆ—IDã‚’ä½¿ç”¨ã—ã¦taxonomyæƒ…å ±ã‚„GO termæƒ…å ±ã¨çµåˆ
  - ãƒ˜ãƒƒãƒ€ãƒ¼å†…ã®è¿½åŠ æƒ…å ±(ã‚‚ã—ã‚ã‚Œã°)ã®æ´»ç”¨
- **æ³¨æ„**: ç¾åœ¨ã¯é…åˆ—ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®è§£æã‚‚æ¤œè¨

#### 6. `go-basic.obo`ã®idã¨nameä»¥å¤–ã®æƒ…å ±
- **å†…å®¹**: GO ontologyã®è©³ç´°æ§‹é€ 
  - `is_a`: è¦ªå­é–¢ä¿‚(éšå±¤æ§‹é€ )
  - `def`: GO termã®å®šç¾©æ–‡
  - `namespace`: biological_process / molecular_function / cellular_component
  - `relationship`: ãã®ä»–ã®é–¢ä¿‚æ€§(part_of, regulatesç­‰)
  - `alt_id`: ä»£æ›¿ID
  - `is_obsolete`: å»ƒæ­¢ã•ã‚ŒãŸGO term
- **ç”¨é€”**:
  - **is_aé–¢ä¿‚**:
    - éšå±¤çš„ãªå¾Œå‡¦ç†(å‰è¿°ã®ã€Œå¾Œå‡¦ç†ã®è¿½åŠ ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‚ç…§)
    - Graph Neural Network (GNN)ã«ã‚ˆã‚‹åŸ‹ã‚è¾¼ã¿å­¦ç¿’
    - äºˆæ¸¬ã®ä¼æ’­: å­ãƒãƒ¼ãƒ‰ã®äºˆæ¸¬ã‹ã‚‰è¦ªãƒãƒ¼ãƒ‰ã®äºˆæ¸¬ã‚’è£œæ­£
  - **def(å®šç¾©æ–‡)**:
    - âœ… ç¾åœ¨ä½¿ç”¨ä¸­: GO termã®nameã¨defã‚’çµåˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆembeddingã‚’ç”Ÿæˆ
    - æ”¹å–„ã®ä½™åœ°: defã®å‰å‡¦ç†æ–¹æ³•ã®æœ€é©åŒ–(å¼•ç”¨ç¬¦é™¤å»ä»¥å¤–ã®æ‰‹æ³•ã‚‚æ¤œè¨)
  - **namespace**:
    - aspectåˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ä½¿ç”¨
  - **relationship**:
    - ã‚ˆã‚Šè¤‡é›‘ãªã‚°ãƒ©ãƒ•æ§‹é€ ã®å­¦ç¿’
    - ç•°ãªã‚‹é–¢ä¿‚æ€§ã«åŸºã¥ãåˆ¶ç´„ã®è¿½åŠ 
  - **is_obsolete**:
    - å»ƒæ­¢ã•ã‚ŒãŸGO termã‚’äºˆæ¸¬å€™è£œã‹ã‚‰é™¤å¤–

#### å®Ÿè£…ã®å„ªå…ˆé †ä½(æ¨å¥¨)
1. **é«˜å„ªå…ˆåº¦**(æœªå®Ÿè£…):
   - `is_a`é–¢ä¿‚: éšå±¤çš„å¾Œå‡¦ç†
   - `namespace`/`aspect`: aspectåˆ¥ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
2. **ä¸­å„ªå…ˆåº¦**(æœªå®Ÿè£…):
   - `IA.tsv`: æå¤±é–¢æ•°ã®é‡ã¿ä»˜ã‘ã‚„ã‚¹ã‚³ã‚¢ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
   - `testsuperset-taxon-list.tsv`: ç”Ÿç‰©ç¨®æ¡ä»¶ä»˜ãäºˆæ¸¬
   - `train_taxonomy.tsv`: ç”Ÿç‰©ç¨®æƒ…å ±ã®embeddingçµ±åˆ
3. **ä½å„ªå…ˆåº¦**(æœªå®Ÿè£…):
   - ãã®ä»–ã®`relationship`: ã‚ˆã‚Šè¤‡é›‘ãªã‚°ãƒ©ãƒ•æ§‹é€ 
   - FASTAãƒ˜ãƒƒãƒ€ãƒ¼ã®è©³ç´°è§£æ

---

